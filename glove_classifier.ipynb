{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from numpy import asarray, zeros\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "This step further cleans the text data by converting text to lowercase, removing punctuation and extra spaces.\n",
    "\n",
    "Certain stopwords affected the sentiment of the text and hence removing them would decrease the accuracy of the model. Furthermore, this project implements a neural network approach and thus\n",
    "1. directional words such as ['above', 'below', 'up', 'down', 'over', 'under']\n",
    "2. words that serves as a negation such as 'can't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('stock_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       " 1    3685\n",
       "-1    2106\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of positive and negative sentiments\n",
    "df['Sentiment'].value_counts() # more positive than negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gareth/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_words = ['above', 'below', 'up', 'down', 'over', 'under']\n",
    "neg_words = ['but', 'no', 'nor', 'not', 'don', \"don't\", 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "exception_words = dir_words + neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process the sentences\n",
    "def process_text(text):\n",
    "    \n",
    "    cleaned = text.lower()\n",
    "\n",
    "    # Remove punctuations\n",
    "    cleaned = re.sub('[^a-zA-Z]', ' ', cleaned)\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "\n",
    "    # Remove stopwords\n",
    "    '''\n",
    "    remove words that affect sentiment from the list of stopwords such as:\n",
    "    ['above', 'below', 'up', 'down', 'over', 'under', 'no', 'nor']\n",
    "    '''\n",
    "    stop_words = [word for word in stopwords.words('english') if word not in exception_words] \n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stop_words) + r')\\b\\s*') \n",
    "    cleaned = pattern.sub('', cleaned)\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user afraid short amzn looking like near monopoly ebooks infrastructure service'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx = \"user I'd be afraid to short AMZN - and they are looking like a near-monopoly in eBooks and infrastructure-as-a-service\"\n",
    "process_text(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kickers watchlist xide tit soq pnk cpw bpz aj ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user aap movie return fea geed indicator trade...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user afraid short amzn looking like near monop...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mnta over</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oi over</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  kickers watchlist xide tit soq pnk cpw bpz aj ...          1\n",
       "1  user aap movie return fea geed indicator trade...          1\n",
       "2  user afraid short amzn looking like near monop...          1\n",
       "3                                         mnta over           1\n",
       "4                                           oi over           1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'] = df['Text'].apply(lambda x: process_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mnta over</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oi over</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pgnx over</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>assuming fcx opens tomorrow above trigger buy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>momentum coming back etfc broke ma resistance ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>investors lose rs lakh crore worst day markets...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5785</th>\n",
       "      <td>tcs share price jumps no layoffs dividend ann...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>gold prices slip below rs investors book prof...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>sharemarket live sensex day high up points ni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>sensex nifty climb day highs still up key fac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "3                                            mnta over           1\n",
       "4                                              oi over           1\n",
       "5                                            pgnx over           1\n",
       "10    assuming fcx opens tomorrow above trigger buy ...          1\n",
       "14    momentum coming back etfc broke ma resistance ...          1\n",
       "...                                                 ...        ...\n",
       "5779  investors lose rs lakh crore worst day markets...         -1\n",
       "5785   tcs share price jumps no layoffs dividend ann...          1\n",
       "5787   gold prices slip below rs investors book prof...         -1\n",
       "5789   sharemarket live sensex day high up points ni...          1\n",
       "5790   sensex nifty climb day highs still up key fac...          1\n",
       "\n",
       "[1797 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the exceptions affects the sentiment\n",
    "df.loc[df['Text'].str.contains(' | '.join(exception_words)),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "y = df['Sentiment'].replace(-1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word freq dict\n",
    "all_words = []\n",
    "\n",
    "for sentence in X:\n",
    "    words = sentence.split()\n",
    "    all_words.extend(words)\n",
    "\n",
    "freq_dist = FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'aap': 929, 'co': 711, 'https': 695, 'user': 646, 'short': 457, 'up': 432, 'over': 352, 'today': 343, 'day': 324, 'volume': 307, ...})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of words with freq <= threshold\n",
    "'''\n",
    "Attempted tweaking the threshold but did not find any significant improvements\n",
    "'''\n",
    "threshold = 0 # threshold for low freq words \n",
    "low_freq_list = []\n",
    "\n",
    "for word, freq in freq_dist.items():\n",
    "    if freq <= threshold: \n",
    "        low_freq_list.append(word)\n",
    "\n",
    "low_freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove words with low freq\n",
    "def remove_low_freq(text):\n",
    "    words = text.split()\n",
    "    removed = [word for word in words if word not in low_freq_list]\n",
    "    return ' '.join(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       kickers watchlist xide tit soq pnk cpw bpz aj ...\n",
       "1       user aap movie return fea geed indicator trade...\n",
       "2       user afraid short amzn looking like near monop...\n",
       "3                                               mnta over\n",
       "4                                                 oi over\n",
       "                              ...                        \n",
       "5786    industry body cii said discoms likely suffer n...\n",
       "5787    gold prices slip below rs investors book profi...\n",
       "5788    workers bajaj auto agreed wage cut period apri...\n",
       "5789    sharemarket live sensex day high up points nif...\n",
       "5790    sensex nifty climb day highs still up key fact...\n",
       "Name: Text, Length: 5791, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.apply(lambda x: remove_low_freq(x))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4632,), (1159,), (4632,), (1159,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80 20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing\n",
    "\n",
    "convert every sentence into an sequences of indexes which represent the words in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Create word to index dictionary\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum sentence length is 22\n"
     ]
    }
   ],
   "source": [
    "maxlen = 0\n",
    "for i in X_train:\n",
    "    if len(i) > maxlen:\n",
    "        maxlen = len(i)\n",
    "for i in X_test:\n",
    "    if len(i) > maxlen:\n",
    "        maxlen = len(i)\n",
    "print(f'The maximum sentence length is {maxlen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aap': 1,\n",
       " 'co': 2,\n",
       " 'https': 3,\n",
       " 'user': 4,\n",
       " 'short': 5,\n",
       " 'up': 6,\n",
       " 'over': 7,\n",
       " 'today': 8,\n",
       " 'volume': 9,\n",
       " 'day': 10,\n",
       " 'long': 11,\n",
       " 'like': 12,\n",
       " 'but': 13,\n",
       " 'not': 14,\n",
       " 'good': 15,\n",
       " 'stock': 16,\n",
       " 'goog': 17,\n",
       " 'watch': 18,\n",
       " 'new': 19,\n",
       " 'still': 20,\n",
       " 'above': 21,\n",
       " 'down': 22,\n",
       " 'stop': 23,\n",
       " 'nice': 24,\n",
       " 'back': 25,\n",
       " 'bac': 26,\n",
       " 'next': 27,\n",
       " 'move': 28,\n",
       " 'market': 29,\n",
       " 'buy': 30,\n",
       " 'time': 31,\n",
       " 'coronavirus': 32,\n",
       " 'see': 33,\n",
       " 'one': 34,\n",
       " 'ong': 35,\n",
       " 'higher': 36,\n",
       " 'no': 37,\n",
       " 'trade': 38,\n",
       " 'week': 39,\n",
       " 'triangle': 40,\n",
       " 'stocks': 41,\n",
       " 'could': 42,\n",
       " 'close': 43,\n",
       " 'weekly': 44,\n",
       " 'sensex': 45,\n",
       " 'looking': 46,\n",
       " 'breakout': 47,\n",
       " 'big': 48,\n",
       " 'nifty': 49,\n",
       " 'support': 50,\n",
       " 'p': 51,\n",
       " 'go': 52,\n",
       " 'break': 53,\n",
       " 'bullish': 54,\n",
       " 'going': 55,\n",
       " 'last': 56,\n",
       " 'looks': 57,\n",
       " 'target': 58,\n",
       " 'nfx': 59,\n",
       " 'green': 60,\n",
       " 'amzn': 61,\n",
       " 'lower': 62,\n",
       " 'gap': 63,\n",
       " 'position': 64,\n",
       " 'highs': 65,\n",
       " 'price': 66,\n",
       " 'markets': 67,\n",
       " 'points': 68,\n",
       " 'earnings': 69,\n",
       " 'f': 70,\n",
       " 'high': 71,\n",
       " 'rt': 72,\n",
       " 'under': 73,\n",
       " 'below': 74,\n",
       " 'get': 75,\n",
       " 'c': 76,\n",
       " 'strong': 77,\n",
       " 'low': 78,\n",
       " 'line': 79,\n",
       " 'may': 80,\n",
       " 'since': 81,\n",
       " 'resistance': 82,\n",
       " 'term': 83,\n",
       " 'amid': 84,\n",
       " 'sell': 85,\n",
       " 'w': 86,\n",
       " 'shares': 87,\n",
       " 'b': 88,\n",
       " 'k': 89,\n",
       " 'think': 90,\n",
       " 'would': 91,\n",
       " 'spy': 92,\n",
       " 'calls': 93,\n",
       " 'first': 94,\n",
       " 'holding': 95,\n",
       " 'cash': 96,\n",
       " 'u': 97,\n",
       " 'ddd': 98,\n",
       " 'trend': 99,\n",
       " 'well': 100,\n",
       " 'take': 101,\n",
       " 'buying': 102,\n",
       " 'open': 103,\n",
       " 'breaking': 104,\n",
       " 'list': 105,\n",
       " 'year': 106,\n",
       " 'tomorrow': 107,\n",
       " 'ma': 108,\n",
       " 'yesterday': 109,\n",
       " 'another': 110,\n",
       " 'flag': 111,\n",
       " 'gs': 112,\n",
       " 'great': 113,\n",
       " 'apple': 114,\n",
       " 'daily': 115,\n",
       " 'v': 116,\n",
       " 'x': 117,\n",
       " 'money': 118,\n",
       " 'look': 119,\n",
       " 'full': 120,\n",
       " 'q': 121,\n",
       " 'coming': 122,\n",
       " 'level': 123,\n",
       " 'street': 124,\n",
       " 'ed': 125,\n",
       " 'entry': 126,\n",
       " 'bought': 127,\n",
       " 'don': 128,\n",
       " 'right': 129,\n",
       " 'imo': 130,\n",
       " 'soon': 131,\n",
       " 'investors': 132,\n",
       " 'call': 133,\n",
       " 'much': 134,\n",
       " 'bank': 135,\n",
       " 'global': 136,\n",
       " 'days': 137,\n",
       " 'bounce': 138,\n",
       " 'run': 139,\n",
       " 'profit': 140,\n",
       " 'oil': 141,\n",
       " 'march': 142,\n",
       " 'red': 143,\n",
       " 'trading': 144,\n",
       " 'around': 145,\n",
       " 'hit': 146,\n",
       " 'million': 147,\n",
       " 'puts': 148,\n",
       " 'news': 149,\n",
       " 'e': 150,\n",
       " 'top': 151,\n",
       " 'hold': 152,\n",
       " 'make': 153,\n",
       " 'pullback': 154,\n",
       " 'znga': 155,\n",
       " 'prices': 156,\n",
       " 'getting': 157,\n",
       " 'cat': 158,\n",
       " 'added': 159,\n",
       " 'option': 160,\n",
       " 'keep': 161,\n",
       " 'also': 162,\n",
       " 'bearish': 163,\n",
       " 'little': 164,\n",
       " 'way': 165,\n",
       " 'post': 166,\n",
       " 'stops': 167,\n",
       " 'nkd': 168,\n",
       " 'growth': 169,\n",
       " 'bottom': 170,\n",
       " 'gains': 171,\n",
       " 'tgt': 172,\n",
       " 'sma': 173,\n",
       " 'years': 174,\n",
       " 'small': 175,\n",
       " 'really': 176,\n",
       " 'pattern': 177,\n",
       " 'bull': 178,\n",
       " 'moving': 179,\n",
       " 'vol': 180,\n",
       " 'put': 181,\n",
       " 'action': 182,\n",
       " 'upside': 183,\n",
       " 'sold': 184,\n",
       " 'friday': 185,\n",
       " 'play': 186,\n",
       " 'h': 187,\n",
       " 'needs': 188,\n",
       " 'trying': 189,\n",
       " 'vs': 190,\n",
       " 'taking': 191,\n",
       " 'says': 192,\n",
       " 'macd': 193,\n",
       " 'better': 194,\n",
       " 'spx': 195,\n",
       " 'know': 196,\n",
       " 'selling': 197,\n",
       " 'feb': 198,\n",
       " 'goes': 199,\n",
       " 'need': 200,\n",
       " 'min': 201,\n",
       " 'sales': 202,\n",
       " 'end': 203,\n",
       " 'share': 204,\n",
       " 'st': 205,\n",
       " 'es': 206,\n",
       " 'possible': 207,\n",
       " 'crisis': 208,\n",
       " 'even': 209,\n",
       " 'fb': 210,\n",
       " 'near': 211,\n",
       " 'pay': 212,\n",
       " 'come': 213,\n",
       " 'start': 214,\n",
       " 'ng': 215,\n",
       " 'fs': 216,\n",
       " 'shot': 217,\n",
       " 'got': 218,\n",
       " 'swing': 219,\n",
       " 'aapl': 220,\n",
       " 'jan': 221,\n",
       " 'company': 222,\n",
       " 'us': 223,\n",
       " 'want': 224,\n",
       " 'jcp': 225,\n",
       " 'morning': 226,\n",
       " 'point': 227,\n",
       " 'bid': 228,\n",
       " 'pandemic': 229,\n",
       " 'th': 230,\n",
       " 'continues': 231,\n",
       " 'key': 232,\n",
       " 'watching': 233,\n",
       " 'test': 234,\n",
       " 'set': 235,\n",
       " 'likely': 236,\n",
       " 'month': 237,\n",
       " 'video': 238,\n",
       " 'scaling': 239,\n",
       " 'drop': 240,\n",
       " 'ssys': 241,\n",
       " 'pop': 242,\n",
       " 'jpm': 243,\n",
       " 'cf': 244,\n",
       " 'many': 245,\n",
       " 'fill': 246,\n",
       " 'heard': 247,\n",
       " 'ema': 248,\n",
       " 'net': 249,\n",
       " 'consolidation': 250,\n",
       " 'making': 251,\n",
       " 'broke': 252,\n",
       " 'might': 253,\n",
       " 'imho': 254,\n",
       " 'two': 255,\n",
       " 'ready': 256,\n",
       " 'de': 257,\n",
       " 'profits': 258,\n",
       " 'china': 259,\n",
       " 'msft': 260,\n",
       " 'si': 261,\n",
       " 'csn': 262,\n",
       " 'best': 263,\n",
       " 'huge': 264,\n",
       " 'say': 265,\n",
       " 'banks': 266,\n",
       " 'setup': 267,\n",
       " 'base': 268,\n",
       " 'average': 269,\n",
       " 'made': 270,\n",
       " 'world': 271,\n",
       " 'add': 272,\n",
       " 'breaks': 273,\n",
       " 'nvda': 274,\n",
       " 'report': 275,\n",
       " 'loss': 276,\n",
       " 'gd': 277,\n",
       " 'g': 278,\n",
       " 'range': 279,\n",
       " 'gmc': 280,\n",
       " 'monthly': 281,\n",
       " 'major': 282,\n",
       " 'ooks': 283,\n",
       " 'people': 284,\n",
       " 'pdating': 285,\n",
       " 'trailing': 286,\n",
       " 'bby': 287,\n",
       " 'shorts': 288,\n",
       " 'channel': 289,\n",
       " 'recent': 290,\n",
       " 'fund': 291,\n",
       " 'positive': 292,\n",
       " 'interesting': 293,\n",
       " 'fed': 294,\n",
       " 'fall': 295,\n",
       " 'done': 296,\n",
       " 'love': 297,\n",
       " 'months': 298,\n",
       " 'lot': 299,\n",
       " 'intraday': 300,\n",
       " 'billion': 301,\n",
       " 'hpq': 302,\n",
       " 'setting': 303,\n",
       " 'r': 304,\n",
       " 'yhoo': 305,\n",
       " 'rbi': 306,\n",
       " 'early': 307,\n",
       " 'via': 308,\n",
       " 'lows': 309,\n",
       " 'maybe': 310,\n",
       " 'data': 311,\n",
       " 'wait': 312,\n",
       " 'follow': 313,\n",
       " 'cup': 314,\n",
       " 'handle': 315,\n",
       " 'far': 316,\n",
       " 'mcp': 317,\n",
       " 'ish': 318,\n",
       " 'economy': 319,\n",
       " 'government': 320,\n",
       " 'hard': 321,\n",
       " 'wants': 322,\n",
       " 'rally': 323,\n",
       " 'n': 324,\n",
       " 'ave': 325,\n",
       " 'spw': 326,\n",
       " 'dollar': 327,\n",
       " 'check': 328,\n",
       " 'rs': 329,\n",
       " 'opens': 330,\n",
       " 'bear': 331,\n",
       " 'worst': 332,\n",
       " 'something': 333,\n",
       " 'away': 334,\n",
       " 'easy': 335,\n",
       " 'prior': 336,\n",
       " 'almost': 337,\n",
       " 'solid': 338,\n",
       " 'thru': 339,\n",
       " 'fcx': 340,\n",
       " 'chk': 341,\n",
       " 'demand': 342,\n",
       " 'cut': 343,\n",
       " 'weeks': 344,\n",
       " 'took': 345,\n",
       " 'area': 346,\n",
       " 'closed': 347,\n",
       " 'financial': 348,\n",
       " 'cheap': 349,\n",
       " 'dividend': 350,\n",
       " 'past': 351,\n",
       " 'bit': 352,\n",
       " 'cost': 353,\n",
       " 'wall': 354,\n",
       " 'uptrend': 355,\n",
       " 'thing': 356,\n",
       " 'business': 357,\n",
       " 'monday': 358,\n",
       " 'companies': 359,\n",
       " 'eps': 360,\n",
       " 'april': 361,\n",
       " 'gpn': 362,\n",
       " 'nicely': 363,\n",
       " 'gold': 364,\n",
       " 'traders': 365,\n",
       " 'adding': 366,\n",
       " 'tight': 367,\n",
       " 'qqq': 368,\n",
       " 'fast': 369,\n",
       " 'ooking': 370,\n",
       " 'watchlist': 371,\n",
       " 'waiting': 372,\n",
       " 'funds': 373,\n",
       " 'probably': 374,\n",
       " 'value': 375,\n",
       " 'work': 376,\n",
       " 'potential': 377,\n",
       " 'cs': 378,\n",
       " 'pcn': 379,\n",
       " 'quarter': 380,\n",
       " 'buys': 381,\n",
       " 'push': 382,\n",
       " 'india': 383,\n",
       " 'ebay': 384,\n",
       " 'opening': 385,\n",
       " 'ibm': 386,\n",
       " 'everyone': 387,\n",
       " 'reversal': 388,\n",
       " 'every': 389,\n",
       " 'hope': 390,\n",
       " 'wmt': 391,\n",
       " 'sure': 392,\n",
       " 'weak': 393,\n",
       " 'signal': 394,\n",
       " 'ist': 395,\n",
       " 'sv': 396,\n",
       " 'head': 397,\n",
       " 'including': 398,\n",
       " 'beating': 399,\n",
       " 'worth': 400,\n",
       " 'economic': 401,\n",
       " 'invn': 402,\n",
       " 'flow': 403,\n",
       " 'bad': 404,\n",
       " 'mar': 405,\n",
       " 'ago': 406,\n",
       " 'qcom': 407,\n",
       " 'vxy': 408,\n",
       " 'jobs': 409,\n",
       " 'pm': 410,\n",
       " 'wow': 411,\n",
       " 'rising': 412,\n",
       " 'bet': 413,\n",
       " 'risk': 414,\n",
       " 'anyone': 415,\n",
       " 'yes': 416,\n",
       " 'due': 417,\n",
       " 'hot': 418,\n",
       " 'oi': 419,\n",
       " 'pretty': 420,\n",
       " 'ms': 421,\n",
       " 'starting': 422,\n",
       " 'deck': 423,\n",
       " 'z': 424,\n",
       " 'said': 425,\n",
       " 'vng': 426,\n",
       " 'negative': 427,\n",
       " 'turn': 428,\n",
       " 'shd': 429,\n",
       " 'dip': 430,\n",
       " 'bar': 431,\n",
       " 'second': 432,\n",
       " 'quick': 433,\n",
       " 'stay': 434,\n",
       " 'avg': 435,\n",
       " 'app': 436,\n",
       " 'wk': 437,\n",
       " 'always': 438,\n",
       " 'overnight': 439,\n",
       " 'squeeze': 440,\n",
       " 'continue': 441,\n",
       " 'already': 442,\n",
       " 'eod': 443,\n",
       " 'doesn': 444,\n",
       " 'side': 445,\n",
       " 'hedge': 446,\n",
       " 'idea': 447,\n",
       " 'lol': 448,\n",
       " 'record': 449,\n",
       " 'working': 450,\n",
       " 'never': 451,\n",
       " 'won': 452,\n",
       " 'rest': 453,\n",
       " 'xco': 454,\n",
       " 'till': 455,\n",
       " 'cee': 456,\n",
       " 'trendline': 457,\n",
       " 'cst': 458,\n",
       " 'hod': 459,\n",
       " 'options': 460,\n",
       " 'swhc': 461,\n",
       " 'industry': 462,\n",
       " 'downside': 463,\n",
       " 'fio': 464,\n",
       " 'momentum': 465,\n",
       " 'expected': 466,\n",
       " 'crore': 467,\n",
       " 'sbx': 468,\n",
       " 'double': 469,\n",
       " 'starts': 470,\n",
       " 'marketupdates': 471,\n",
       " 'mon': 472,\n",
       " 'trader': 473,\n",
       " 'late': 474,\n",
       " 'ever': 475,\n",
       " 'per': 476,\n",
       " 'analysis': 477,\n",
       " 'let': 478,\n",
       " 'pre': 479,\n",
       " 'went': 480,\n",
       " 'ana': 481,\n",
       " 'eye': 482,\n",
       " 'cross': 483,\n",
       " 'biggest': 484,\n",
       " 'trades': 485,\n",
       " 'falling': 486,\n",
       " 'candle': 487,\n",
       " 'portfolio': 488,\n",
       " 'mtg': 489,\n",
       " 'heavy': 490,\n",
       " 'half': 491,\n",
       " 'tc': 492,\n",
       " 'triggered': 493,\n",
       " 'buyers': 494,\n",
       " 'split': 495,\n",
       " 'building': 496,\n",
       " 'falls': 497,\n",
       " 'continuation': 498,\n",
       " 'following': 499,\n",
       " 'dump': 500,\n",
       " 'hits': 501,\n",
       " 'wfc': 502,\n",
       " 'fib': 503,\n",
       " 'swy': 504,\n",
       " 'oversold': 505,\n",
       " 'large': 506,\n",
       " 'oc': 507,\n",
       " 'finally': 508,\n",
       " 'posted': 509,\n",
       " 'free': 510,\n",
       " 'though': 511,\n",
       " 'gets': 512,\n",
       " 'positions': 513,\n",
       " 'imm': 514,\n",
       " 'operational': 515,\n",
       " 'ow': 516,\n",
       " 'despite': 517,\n",
       " 'beat': 518,\n",
       " 'size': 519,\n",
       " 'sorry': 520,\n",
       " 'oh': 521,\n",
       " 'ceo': 522,\n",
       " 'apo': 523,\n",
       " 'hour': 524,\n",
       " 'additions': 525,\n",
       " 'gevo': 526,\n",
       " 'show': 527,\n",
       " 'weakness': 528,\n",
       " 'dma': 529,\n",
       " 'pick': 530,\n",
       " 'levels': 531,\n",
       " 'samsung': 532,\n",
       " 'lockdowns': 533,\n",
       " 'lockdown': 534,\n",
       " 'showing': 535,\n",
       " 'pt': 536,\n",
       " 'cap': 537,\n",
       " 'aa': 538,\n",
       " 'interest': 539,\n",
       " 'bulls': 540,\n",
       " 'update': 541,\n",
       " 'dow': 542,\n",
       " 'inflation': 543,\n",
       " 'surge': 544,\n",
       " 'gae': 545,\n",
       " 'shorting': 546,\n",
       " 'yet': 547,\n",
       " 'give': 548,\n",
       " 'try': 549,\n",
       " 'real': 550,\n",
       " 'thursday': 551,\n",
       " 'dndn': 552,\n",
       " 'jump': 553,\n",
       " 'game': 554,\n",
       " 'covered': 555,\n",
       " 'left': 556,\n",
       " 'expect': 557,\n",
       " 'expectations': 558,\n",
       " 'deal': 559,\n",
       " 'aig': 560,\n",
       " 'pos': 561,\n",
       " 'wrap': 562,\n",
       " 'mkt': 563,\n",
       " 'iphone': 564,\n",
       " 'covid': 565,\n",
       " 'debt': 566,\n",
       " 'minute': 567,\n",
       " 'others': 568,\n",
       " 'clear': 569,\n",
       " 'broken': 570,\n",
       " 'current': 571,\n",
       " 'bears': 572,\n",
       " 'ha': 573,\n",
       " 'ends': 574,\n",
       " 'gmx': 575,\n",
       " 'j': 576,\n",
       " 'january': 577,\n",
       " 'bonds': 578,\n",
       " 'bvsn': 579,\n",
       " 'ahead': 580,\n",
       " 'europe': 581,\n",
       " 'lets': 582,\n",
       " 'win': 583,\n",
       " 'indicators': 584,\n",
       " 'sd': 585,\n",
       " 'expiration': 586,\n",
       " 'consumer': 587,\n",
       " 'started': 588,\n",
       " 'patience': 589,\n",
       " 'ove': 590,\n",
       " 'failed': 591,\n",
       " 'kbh': 592,\n",
       " 'ft': 593,\n",
       " 'missed': 594,\n",
       " 'kos': 595,\n",
       " 'dead': 596,\n",
       " 'less': 597,\n",
       " 'cloud': 598,\n",
       " 'businesses': 599,\n",
       " 'l': 600,\n",
       " 'dvax': 601,\n",
       " 'minutes': 602,\n",
       " 'cover': 603,\n",
       " 'night': 604,\n",
       " 'technicals': 605,\n",
       " 'saying': 606,\n",
       " 'correction': 607,\n",
       " 'return': 608,\n",
       " 'comes': 609,\n",
       " 'overbought': 610,\n",
       " 'everything': 611,\n",
       " 'beats': 612,\n",
       " 'tonight': 613,\n",
       " 'gain': 614,\n",
       " 'yr': 615,\n",
       " 'intc': 616,\n",
       " 'seems': 617,\n",
       " 'losses': 618,\n",
       " 'mo': 619,\n",
       " 'affy': 620,\n",
       " 'home': 621,\n",
       " 'story': 622,\n",
       " 'gonna': 623,\n",
       " 'note': 624,\n",
       " 'en': 625,\n",
       " 'downtrend': 626,\n",
       " 'div': 627,\n",
       " 'rupee': 628,\n",
       " 'without': 629,\n",
       " 'hate': 630,\n",
       " 'compq': 631,\n",
       " 'technical': 632,\n",
       " 'dia': 633,\n",
       " 'leg': 634,\n",
       " 'dec': 635,\n",
       " 'headed': 636,\n",
       " 'earlier': 637,\n",
       " 'rise': 638,\n",
       " 'dnkn': 639,\n",
       " 'straight': 640,\n",
       " 'cm': 641,\n",
       " 'wsj': 642,\n",
       " 'slow': 643,\n",
       " 'nearly': 644,\n",
       " 'called': 645,\n",
       " 'divergence': 646,\n",
       " 'saudi': 647,\n",
       " 'didn': 648,\n",
       " 'pull': 649,\n",
       " 'step': 650,\n",
       " 'vmw': 651,\n",
       " 'decline': 652,\n",
       " 'largest': 653,\n",
       " 'retest': 654,\n",
       " 'old': 655,\n",
       " 'help': 656,\n",
       " 'qco': 657,\n",
       " 'sector': 658,\n",
       " 'tv': 659,\n",
       " 'cents': 660,\n",
       " 'happens': 661,\n",
       " 'reason': 662,\n",
       " 'catch': 663,\n",
       " 'volatility': 664,\n",
       " 'blog': 665,\n",
       " 'results': 666,\n",
       " 'three': 667,\n",
       " 'mark': 668,\n",
       " 'group': 669,\n",
       " 'either': 670,\n",
       " 'plan': 671,\n",
       " 'pphm': 672,\n",
       " 'book': 673,\n",
       " 'rebound': 674,\n",
       " 'cuts': 675,\n",
       " 'tech': 676,\n",
       " 'times': 677,\n",
       " 'wynn': 678,\n",
       " 'sca': 679,\n",
       " 'sa': 680,\n",
       " 'power': 681,\n",
       " 'february': 682,\n",
       " 'se': 683,\n",
       " 'targets': 684,\n",
       " 'eading': 685,\n",
       " 'ax': 686,\n",
       " 'someone': 687,\n",
       " 'float': 688,\n",
       " 'giving': 689,\n",
       " 'place': 690,\n",
       " 'miss': 691,\n",
       " 'ook': 692,\n",
       " 'sellers': 693,\n",
       " 'enough': 694,\n",
       " 'drops': 695,\n",
       " 'least': 696,\n",
       " 'gdx': 697,\n",
       " 'roll': 698,\n",
       " 'nothing': 699,\n",
       " 'gas': 700,\n",
       " 'yrs': 701,\n",
       " 'po': 702,\n",
       " 'smart': 703,\n",
       " 'use': 704,\n",
       " 'yep': 705,\n",
       " 'forming': 706,\n",
       " 'mean': 707,\n",
       " 'agree': 708,\n",
       " 'shows': 709,\n",
       " 'retail': 710,\n",
       " 'pivot': 711,\n",
       " 'setups': 712,\n",
       " 'kwk': 713,\n",
       " 'online': 714,\n",
       " 'spot': 715,\n",
       " 'held': 716,\n",
       " 'hours': 717,\n",
       " 'lost': 718,\n",
       " 'vhc': 719,\n",
       " 'lots': 720,\n",
       " 'ipad': 721,\n",
       " 'coh': 722,\n",
       " 'governor': 723,\n",
       " 'closing': 724,\n",
       " 'crude': 725,\n",
       " 'ratio': 726,\n",
       " 'state': 727,\n",
       " 'seen': 728,\n",
       " 'mentioned': 729,\n",
       " 'hd': 730,\n",
       " 'impact': 731,\n",
       " 'px': 732,\n",
       " 'tsa': 733,\n",
       " 'closes': 734,\n",
       " 'equity': 735,\n",
       " 'increased': 736,\n",
       " 'poised': 737,\n",
       " 'holds': 738,\n",
       " 'american': 739,\n",
       " 'ocn': 740,\n",
       " 'tap': 741,\n",
       " 'within': 742,\n",
       " 'gdp': 743,\n",
       " 'loans': 744,\n",
       " 'premarket': 745,\n",
       " 'longs': 746,\n",
       " 'federal': 747,\n",
       " 'cmg': 748,\n",
       " 'central': 749,\n",
       " 'radar': 750,\n",
       " 'box': 751,\n",
       " 'confirming': 752,\n",
       " 'must': 753,\n",
       " 'thanks': 754,\n",
       " 'zone': 755,\n",
       " 'amazon': 756,\n",
       " 'thought': 757,\n",
       " 'haven': 758,\n",
       " 'ctic': 759,\n",
       " 'ideas': 760,\n",
       " 'cox': 761,\n",
       " 'nke': 762,\n",
       " 'trigger': 763,\n",
       " 'nx': 764,\n",
       " 'byd': 765,\n",
       " 'vvs': 766,\n",
       " 'csco': 767,\n",
       " 'upper': 768,\n",
       " 'expecting': 769,\n",
       " 'anad': 770,\n",
       " 'lead': 771,\n",
       " 'bond': 772,\n",
       " 'investment': 773,\n",
       " 'later': 774,\n",
       " 'selloff': 775,\n",
       " 'ca': 776,\n",
       " 'betting': 777,\n",
       " 'south': 778,\n",
       " 'sk': 779,\n",
       " 'das': 780,\n",
       " 'ko': 781,\n",
       " 'climb': 782,\n",
       " 'came': 783,\n",
       " 'ok': 784,\n",
       " 'worse': 785,\n",
       " 'part': 786,\n",
       " 'change': 787,\n",
       " 'rate': 788,\n",
       " 'stoploss': 789,\n",
       " 'reserve': 790,\n",
       " 'believe': 791,\n",
       " 'massive': 792,\n",
       " 'supply': 793,\n",
       " 'based': 794,\n",
       " 'decent': 795,\n",
       " 'increase': 796,\n",
       " 'hes': 797,\n",
       " 'spread': 798,\n",
       " 'nd': 799,\n",
       " 'trap': 800,\n",
       " 'ndx': 801,\n",
       " 'pressure': 802,\n",
       " 'breakouts': 803,\n",
       " 'remain': 804,\n",
       " 'health': 805,\n",
       " 'pin': 806,\n",
       " 'confirmation': 807,\n",
       " 'view': 808,\n",
       " 'stream': 809,\n",
       " 'bets': 810,\n",
       " 'solar': 811,\n",
       " 'signs': 812,\n",
       " 'futures': 813,\n",
       " 'ec': 814,\n",
       " 'fly': 815,\n",
       " 'alert': 816,\n",
       " 'isn': 817,\n",
       " 'ceg': 818,\n",
       " 'claims': 819,\n",
       " 'numbers': 820,\n",
       " 'longer': 821,\n",
       " 'name': 822,\n",
       " 'recession': 823,\n",
       " 'consolidating': 824,\n",
       " 'panic': 825,\n",
       " 'enter': 826,\n",
       " 'wt': 827,\n",
       " 'offer': 828,\n",
       " 'fresh': 829,\n",
       " 'sitting': 830,\n",
       " 'amp': 831,\n",
       " 'traded': 832,\n",
       " 'estimates': 833,\n",
       " 'cog': 834,\n",
       " 'saw': 835,\n",
       " 'cen': 836,\n",
       " 'opex': 837,\n",
       " 'bot': 838,\n",
       " 'ot': 839,\n",
       " 'hammer': 840,\n",
       " 'corporate': 841,\n",
       " 'told': 842,\n",
       " 'flags': 843,\n",
       " 'tell': 844,\n",
       " 'future': 845,\n",
       " 'wonder': 846,\n",
       " 'please': 847,\n",
       " 'along': 848,\n",
       " 'shoulders': 849,\n",
       " 'lose': 850,\n",
       " 'crossing': 851,\n",
       " 'sto': 852,\n",
       " 'public': 853,\n",
       " 'momo': 854,\n",
       " 'previous': 855,\n",
       " 'chinese': 856,\n",
       " 'mobile': 857,\n",
       " 'space': 858,\n",
       " 'aid': 859,\n",
       " 'ngt': 860,\n",
       " 'ppl': 861,\n",
       " 'inside': 862,\n",
       " 'vz': 863,\n",
       " 'fnfg': 864,\n",
       " 'cook': 865,\n",
       " 'employees': 866,\n",
       " 'dt': 867,\n",
       " 'shaktikanta': 868,\n",
       " 'anybody': 869,\n",
       " 'mos': 870,\n",
       " 'keeping': 871,\n",
       " 'confirmed': 872,\n",
       " 'inc': 873,\n",
       " 'sharing': 874,\n",
       " 'margin': 875,\n",
       " 'guys': 876,\n",
       " 'axp': 877,\n",
       " 'phone': 878,\n",
       " 'strength': 879,\n",
       " 'peix': 880,\n",
       " 'rises': 881,\n",
       " 'buyer': 882,\n",
       " 'staying': 883,\n",
       " 'block': 884,\n",
       " 'gme': 885,\n",
       " 'guess': 886,\n",
       " 'wen': 887,\n",
       " 'heading': 888,\n",
       " 'management': 889,\n",
       " 'seeing': 890,\n",
       " 'calling': 891,\n",
       " 'kcg': 892,\n",
       " 'tuesday': 893,\n",
       " 'capital': 894,\n",
       " 'weekend': 895,\n",
       " 'find': 896,\n",
       " 'else': 897,\n",
       " 'dollars': 898,\n",
       " 'bk': 899,\n",
       " 'fears': 900,\n",
       " 'ampe': 901,\n",
       " 'ay': 902,\n",
       " 'arabia': 903,\n",
       " 'fight': 904,\n",
       " 'einhorn': 905,\n",
       " 'dont': 906,\n",
       " 'leading': 907,\n",
       " 'door': 908,\n",
       " 'nov': 909,\n",
       " 'lagging': 910,\n",
       " 'whole': 911,\n",
       " 'hf': 912,\n",
       " 'social': 913,\n",
       " 'delta': 914,\n",
       " 'margins': 915,\n",
       " 'body': 916,\n",
       " 'third': 917,\n",
       " 'apc': 918,\n",
       " 'gt': 919,\n",
       " 'matter': 920,\n",
       " 'scale': 921,\n",
       " 'breakdown': 922,\n",
       " 'declining': 923,\n",
       " 'google': 924,\n",
       " 'investments': 925,\n",
       " 'vome': 926,\n",
       " 'morgan': 927,\n",
       " 'paying': 928,\n",
       " 'mako': 929,\n",
       " 'russia': 930,\n",
       " 'rd': 931,\n",
       " 'goldman': 932,\n",
       " 'sign': 933,\n",
       " 'wsjheard': 934,\n",
       " 'means': 935,\n",
       " 'bars': 936,\n",
       " 'ascending': 937,\n",
       " 'progress': 938,\n",
       " 'alpha': 939,\n",
       " 'pulling': 940,\n",
       " 'lakh': 941,\n",
       " 'descending': 942,\n",
       " 'liquidity': 943,\n",
       " 'seem': 944,\n",
       " 'analysts': 945,\n",
       " 'csod': 946,\n",
       " 'ugly': 947,\n",
       " 'hopes': 948,\n",
       " 'things': 949,\n",
       " 'mgm': 950,\n",
       " 'virus': 951,\n",
       " 'dis': 952,\n",
       " 'im': 953,\n",
       " 'filled': 954,\n",
       " 'create': 955,\n",
       " 'balance': 956,\n",
       " 'remember': 957,\n",
       " 'chance': 958,\n",
       " 'opportunity': 959,\n",
       " 'acting': 960,\n",
       " 'light': 961,\n",
       " 'period': 962,\n",
       " 'crash': 963,\n",
       " 'needed': 964,\n",
       " 'investor': 965,\n",
       " 'picks': 966,\n",
       " 'continuing': 967,\n",
       " 'kex': 968,\n",
       " 'sells': 969,\n",
       " 'moves': 970,\n",
       " 'crosses': 971,\n",
       " 'credit': 972,\n",
       " 'dn': 973,\n",
       " 'activity': 974,\n",
       " 'upward': 975,\n",
       " 'makes': 976,\n",
       " 'appears': 977,\n",
       " 'stake': 978,\n",
       " 'expects': 979,\n",
       " 'ts': 980,\n",
       " 'software': 981,\n",
       " 'hanging': 982,\n",
       " 'eady': 983,\n",
       " 'technology': 984,\n",
       " 'total': 985,\n",
       " 'xf': 986,\n",
       " 'countries': 987,\n",
       " 'begin': 988,\n",
       " 'hek': 989,\n",
       " 'finance': 990,\n",
       " 'invest': 991,\n",
       " 'signals': 992,\n",
       " 'slump': 993,\n",
       " 'anything': 994,\n",
       " 'instead': 995,\n",
       " 'resume': 996,\n",
       " 'prefer': 997,\n",
       " 'wfm': 998,\n",
       " 'vxx': 999,\n",
       " 'exposure': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8026"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of unique words\n",
    "vocab_size = len(tokenizer.word_index) + 1 # for glove\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill sentences with len < maxlen with 0s\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8026, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GloVe Embeddings\n",
    "embeddings_dict = dict()\n",
    "glove_file = open('glove_files/glove.6B.50d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = asarray(values[1:], dtype='float32')\n",
    "    embeddings_dict[word] = vector\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_size, 50))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4632, 22), (1159, 22))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape = (num of rows, maxlen)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation\n",
    "\n",
    "An LSTM is used as the words are treated as 'timesteps' where each word affects subsequent inputs.\n",
    "\n",
    "Avoided overfitting by reducing epochs and layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARS\n",
    "EPOCHS = 4 #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 20:54:03.062013: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2023-12-14 20:54:03.062046: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-14 20:54:03.062053: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-14 20:54:03.062330: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-14 20:54:03.062785: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 22, 50)            401300    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                29440     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 430805 (1.64 MB)\n",
      "Trainable params: 430805 (1.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = keras.Sequential([\n",
    "\n",
    "    keras.layers.Embedding(input_dim=vocab_size, output_dim=50, weights=[embedding_matrix], input_length=maxlen), # GloVe embeddings\n",
    "    keras.layers.LSTM(units=64, activation='relu'),\n",
    "    keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 20:54:03.848100: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 61s 520ms/step - loss: 0.6510 - accuracy: 0.6413 - val_loss: 0.6170 - val_accuracy: 0.6731\n",
      "Epoch 2/4\n",
      "116/116 [==============================] - 60s 520ms/step - loss: 0.5628 - accuracy: 0.7126 - val_loss: 0.5511 - val_accuracy: 0.7184\n",
      "Epoch 3/4\n",
      "116/116 [==============================] - 60s 519ms/step - loss: 0.4404 - accuracy: 0.7965 - val_loss: 0.5475 - val_accuracy: 0.7087\n",
      "Epoch 4/4\n",
      "116/116 [==============================] - 55s 471ms/step - loss: 0.3274 - accuracy: 0.8588 - val_loss: 0.6687 - val_accuracy: 0.7605\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=EPOCHS, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 2s 49ms/step - loss: 0.6254 - accuracy: 0.7808\n",
      "Test accuracy: 0.780845582485199\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(X_test, y_test)\n",
    "test_loss, test_acc = test_eval[0], test_eval[1]\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
